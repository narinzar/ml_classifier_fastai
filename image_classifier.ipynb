[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/narinzar/ml_classifier_fastai/blob/main/image_classifier.ipynb)
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detailed Guide to Image Classification with fastai for Beginners\n",
    "\n",
    "This notebook provides a detailed guide to building an image classifier using the fastai library. We'll cover each step thoroughly, explaining key concepts as we go."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setting Up the Environment\n",
    "\n",
    "First, we need to install the fastai library and its dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install fastai\n",
    "!pip install fastai\n",
    "\n",
    "# Import necessary libraries\n",
    "from fastai.vision.all import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Getting the Data\n",
    "\n",
    "There are several ways to get data for your image classifier. We'll use the Oxford-IIIT Pet Dataset, which contains images of cats and dogs of 37 different breeds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download and extract a built-in dataset\n",
    "path = untar_data(URLs.PETS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Understanding Your Data: Exploratory Data Analysis\n",
    "\n",
    "Before building any model, it's crucial to understand your data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get list of image files\n",
    "files = get_image_files(path/\"images\")\n",
    "\n",
    "# Print number of images\n",
    "print(f\"Total number of images: {len(files)}\")\n",
    "\n",
    "# Print first few filenames to understand naming pattern\n",
    "print(\"Sample filenames:\")\n",
    "for i, file in enumerate(files[:5]):\n",
    "    print(f\"  {i+1}. {file.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Looking at Image Dimensions and Formats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import random\n",
    "\n",
    "# Sample a few random images\n",
    "sample_files = random.sample(files, 5)\n",
    "\n",
    "print(\"Sample image details:\")\n",
    "for file in sample_files:\n",
    "    img = Image.open(file)\n",
    "    print(f\"Filename: {file.name}, Size: {img.size}, Format: {img.format}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examining Class Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If classes are in folders\n",
    "if (path/\"images\").ls()[0].is_dir():\n",
    "    classes = [d.name for d in (path/\"images\").ls() if d.is_dir()]\n",
    "    print(f\"Classes: {classes}\")\n",
    "    \n",
    "    # Count images per class\n",
    "    class_counts = {}\n",
    "    for cls in classes:\n",
    "        class_counts[cls] = len(list((path/\"images\"/cls).ls()))\n",
    "    \n",
    "    for cls, count in class_counts.items():\n",
    "        print(f\"Class {cls}: {count} images\")\n",
    "\n",
    "# If classes are in filenames (like in the Pets dataset)\n",
    "else:\n",
    "    # Extract breed name from filename\n",
    "    def get_breed(filename):\n",
    "        return '_'.join(filename.split('_')[:-1])\n",
    "    \n",
    "    # Count images per breed\n",
    "    breed_counts = {}\n",
    "    for file in files:\n",
    "        breed = get_breed(file.name)\n",
    "        if breed in breed_counts:\n",
    "            breed_counts[breed] += 1\n",
    "        else:\n",
    "            breed_counts[breed] = 1\n",
    "    \n",
    "    print(f\"Total number of breeds: {len(breed_counts)}\")\n",
    "    \n",
    "    # Display a few examples\n",
    "    print(\"Sample breed counts:\")\n",
    "    for i, (breed, count) in enumerate(list(breed_counts.items())[:5]):\n",
    "        print(f\"  {i+1}. {breed}: {count} images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing Sample Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "\n",
    "for i, file in enumerate(sample_files):\n",
    "    img = Image.open(file)\n",
    "    plt.subplot(2, 3, i+1)\n",
    "    plt.imshow(img)\n",
    "    plt.title(get_breed(file.name).replace('_', ' ').title())\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Preprocessing and DataLoaders\n",
    "\n",
    "### Understanding DataLoaders\n",
    "\n",
    "DataLoaders handle the data pipeline, including loading images in batches, applying transformations, splitting data into training and validation sets, and providing iterators for model training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define how to extract labels from filenames\n",
    "def get_label(filename):\n",
    "    return '_'.join(filename.name.split('_')[:-1])\n",
    "\n",
    "# Create DataLoaders\n",
    "dls = ImageDataLoaders.from_name_func(\n",
    "    path,                  # Path to the data directory\n",
    "    files,                 # List of image files\n",
    "    get_label,             # Function to get label from filename\n",
    "    valid_pct=0.2,         # Use 20% of data for validation\n",
    "    seed=42,               # Random seed for reproducibility\n",
    "    item_tfms=Resize(224), # Resize all images to 224x224 pixels\n",
    "    batch_size=32          # Process 32 images at a time\n",
    ")\n",
    "\n",
    "# Check classes\n",
    "print(f\"Classes: {dls.vocab}\")\n",
    "print(f\"Total classes: {len(dls.vocab)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic transformations (resize only)\n",
    "dls_basic = ImageDataLoaders.from_name_func(\n",
    "    path, files, get_label,\n",
    "    item_tfms=Resize(224),    # Resize each image to 224x224\n",
    "    valid_pct=0.2\n",
    ")\n",
    "\n",
    "# Advanced transformations (with data augmentation)\n",
    "dls_aug = ImageDataLoaders.from_name_func(\n",
    "    path, files, get_label,\n",
    "    item_tfms=Resize(224),    # Resize each image\n",
    "    batch_tfms=aug_transforms(  # Apply these augmentations to each batch\n",
    "        mult=2,                # Intensity multiplier\n",
    "        do_flip=True,          # Random horizontal flips\n",
    "        flip_vert=False,       # No vertical flips\n",
    "        max_rotate=10.0,       # Max rotation angle (degrees)\n",
    "        min_zoom=1.0,          # Min zoom factor\n",
    "        max_zoom=1.1,          # Max zoom factor\n",
    "        max_lighting=0.2,      # Max lighting adjustment\n",
    "        max_warp=0.2           # Max warp adjustment\n",
    "    ),\n",
    "    valid_pct=0.2\n",
    ")\n",
    "\n",
    "# Visualize a batch with and without augmentation\n",
    "plt.figure(figsize=(12, 10))\n",
    "plt.subplot(1, 2, 1)\n",
    "dls_basic.show_batch(max_n=9, nrows=3, ncols=3, figsize=(10, 10), title=\"Without Augmentation\")\n",
    "plt.subplot(1, 2, 2)\n",
    "dls_aug.show_batch(max_n=9, nrows=3, ncols=3, figsize=(10, 10), title=\"With Augmentation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Understanding Transfer Learning and Model Architecture\n",
    "\n",
    "### What is Transfer Learning?\n",
    "\n",
    "Transfer learning involves taking a model trained on a large dataset (like ImageNet) and adapting it to your specific task. This works because early layers of deep neural networks learn general features (edges, textures), while later layers learn more task-specific features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a learner with a pre-trained ResNet34 model\n",
    "learn = vision_learner(\n",
    "    dls,             # Our DataLoaders\n",
    "    resnet34,        # The architecture to use (ResNet with 34 layers)\n",
    "    pretrained=True, # Use weights pre-trained on ImageNet\n",
    "    metrics=error_rate  # Metric to track during training\n",
    ")\n",
    "\n",
    "# Examine the model architecture\n",
    "print(learn.model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding the Model Architecture\n",
    "\n",
    "ResNet34 consists of:\n",
    "\n",
    "- A stem (initial convolution layers)\n",
    "- Four blocks of residual layers\n",
    "- An adaptive pooling layer\n",
    "- A fully connected (linear) head\n",
    "\n",
    "When using `vision_learner`, fastai:\n",
    "\n",
    "- Takes the pre-trained ResNet\n",
    "- Removes the final layer (designed for 1000 ImageNet classes)\n",
    "- Adds a new head with a layer matching your number of classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the model's layer groups\n",
    "print(\"Model layer groups:\")\n",
    "for i, layer_group in enumerate(learn.model):\n",
    "    print(f\"Group {i+1}: {layer_group}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Training the Model: Understanding Fine-Tuning\n",
    "\n",
    "### What is Fine-Tuning?\n",
    "\n",
    "Fine-tuning has two phases:\n",
    "\n",
    "1. **Freeze**: Train only the new head, keeping pre-trained weights frozen.\n",
    "2. **Unfreeze**: Gradually train all layers, with lower learning rates for earlier layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Finding a Good Learning Rate\n",
    "\n",
    "The learning rate controls how quickly the model updates its weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find optimal learning rate\n",
    "learn.lr_find()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Train the Head (Freeze)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train only the head for 1 epoch\n",
    "learn.fit_one_cycle(1, 3e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Fine-Tune the Entire Model (Unfreeze)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unfreeze all layers\n",
    "learn.unfreeze()\n",
    "\n",
    "# Train with different learning rates for different layer groups\n",
    "learn.fit_one_cycle(4, lr_max=slice(1e-5, 1e-3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is an Epoch?\n",
    "\n",
    "An epoch is one complete pass through the entire training dataset. During each epoch:\n",
    "\n",
    "- The model sees every training image once\n",
    "- Updates its weights based on the errors it makes\n",
    "- Checks its performance on the validation set\n",
    "\n",
    "Multiple epochs are needed because:\n",
    "\n",
    "- The model learns incrementally\n",
    "- Random batching means each epoch presents data in a different order\n",
    "- With data augmentation, the model sees different versions of images\n",
    "\n",
    "### Understanding the Training Output\n",
    "\n",
    "During training, fastai shows:\n",
    "\n",
    "- `epoch`: Current epoch number\n",
    "- `train_loss`: Average loss on training data\n",
    "- `valid_loss`: Average loss on validation data\n",
    "- `error_rate`: Percentage of validation images misclassified\n",
    "- `time`: Time taken for the epoch\n",
    "\n",
    "A decreasing validation loss means the model is learning. If validation loss increases while training loss continues to decrease, the model is overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Model Evaluation and Interpretation\n",
    "\n",
    "### Understanding the Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an interpretation object\n",
    "interp = ClassificationInterpretation.from_learner(learn)\n",
    "\n",
    "# Plot confusion matrix\n",
    "interp.plot_confusion_matrix(figsize=(12, 12), dpi=60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A confusion matrix shows:\n",
    "\n",
    "- Rows: Actual classes\n",
    "- Columns: Predicted classes\n",
    "- Diagonal: Correct predictions\n",
    "- Off-diagonal: Mistakes\n",
    "\n",
    "Brighter colors indicate more samples. Ideally, most brightness should be on the diagonal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top Losses Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show images with highest loss values\n",
    "interp.plot_top_losses(9, figsize=(15, 11))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each image, it shows:\n",
    "\n",
    "- Predicted class\n",
    "- Actual class\n",
    "- Loss value\n",
    "- Probability of actual class\n",
    "\n",
    "This helps identify:\n",
    "\n",
    "- Mislabeled data\n",
    "- Genuinely difficult cases\n",
    "- Patterns in model mistakes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Most Confused Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show most confused class pairs\n",
    "interp.most_confused(min_val=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This shows pairs of classes the model confuses most often."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Making Predictions and Using the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Make a prediction on a new image\n",
    "img = PILImage.create('path/to/new/image.jpg')\n",
    "\n",
    "# Predict\n",
    "pred, pred_idx, probs = learn.predict(img)\n",
    "\n",
    "# Display results\n",
    "print(f\"Prediction: {pred}\")\n",
    "print(f\"Probability: {probs[pred_idx]:.4f}\")\n",
    "\n",
    "# Show image with prediction\n",
    "img.show()\n",
    "print(f\"Predicted: {pred}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Practical Exercise: Building Your Own Classifier\n",
    "\n",
    "Let's put it all together with a simple pet classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Get data\n",
    "path = untar_data(URLs.PETS)\n",
    "files = get_image_files(path/\"images\")\n",
    "\n",
    "# 2. Define label function\n",
    "def get_label(file): return '_'.join(file.name.split('_')[:-1])\n",
    "\n",
    "# 3. Create DataLoaders\n",
    "dls = ImageDataLoaders.from_name_func(\n",
    "    path, files, get_label,\n",
    "    item_tfms=Resize(224),\n",
    "    batch_tfms=aug_transforms(size=224, min_scale=0.8),\n",
    "    valid_pct=0.2\n",
    ")\n",
    "\n",
    "# 4. Check data\n",
    "dls.show_batch(max_n=9, figsize=(12, 10))\n",
    "\n",
    "# 5. Create learner\n",
    "learn = vision_learner(dls, resnet34, metrics=error_rate)\n",
    "\n",
    "# 6. Find good learning rate\n",
    "learn.lr_find()\n",
    "\n",
    "# 7. Train head\n",
    "learn.fit_one_cycle(1, 3e-3)\n",
    "\n",
    "# 8. Fine-tune entire model\n",
    "learn.unfreeze()\n",
    "learn.fit_one_cycle(4, slice(1e-5, 1e-3))\n",
    "\n",
    "# 9. Evaluate results\n",
    "interp = ClassificationInterpretation.from_learner(learn)\n",
    "interp.plot_confusion_matrix()\n",
    "interp.plot_top_losses(9)\n",
    "\n",
    "# 10. Save model\n",
    "learn.export('pet_classifier.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Advanced Techniques for Improving Performance\n",
    "\n",
    "### Using Different Architectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try a more powerful architecture\n",
    "learn_resnet50 = vision_learner(dls, resnet50, metrics=error_rate)\n",
    "learn_resnet50.fine_tune(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Progressive Resizing\n",
    "\n",
    "Train on smaller images first, then larger ones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First train on smaller images\n",
    "dls_small = ImageDataLoaders.from_name_func(\n",
    "    path, files, get_label,\n",
    "    item_tfms=Resize(128),\n",
    "    batch_tfms=aug_transforms(size=128),\n",
    "    valid_pct=0.2\n",
    ")\n",
    "learn_prog = vision_learner(dls_small, resnet34, metrics=error_rate)\n",
    "learn_prog.fine_tune(3)\n",
    "\n",
    "# Then move to larger images\n",
    "dls_large = ImageDataLoaders.from_name_func(\n",
    "    path, files, get_label,\n",
    "    item_tfms=Resize(224),\n",
    "    batch_tfms=aug_transforms(size=224),\n",
    "    valid_pct=0.2\n",
    ")\n",
    "learn_prog.dls = dls_large\n",
    "learn_prog.fine_tune(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Time Augmentation (TTA)\n",
    "\n",
    "Make predictions on augmented versions of test images and average results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regular prediction\n",
    "pred, pred_idx, probs = learn.predict(img)\n",
    "print(f\"Regular prediction: {pred}, Confidence: {probs[pred_idx]:.4f}\")\n",
    "\n",
    "# Prediction with TTA\n",
    "preds, _, probs = learn.tta(img)\n",
    "print(f\"TTA prediction: {preds[0]}, Confidence: {probs[0][0]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Concepts Explained\n",
    "\n",
    "### Overfitting vs. Underfitting\n",
    "\n",
    "- **Underfitting**: Model is too simple, performs poorly on both training and validation.\n",
    "- **Overfitting**: Model memorizes training data but generalizes poorly (good training metrics, poor validation).\n",
    "\n",
    "### Loss Functions\n",
    "\n",
    "The loss function measures how wrong the model's predictions are:\n",
    "\n",
    "- **CrossEntropyLoss**: Standard for classification (measures how far predictions are from the correct class).\n",
    "\n",
    "### Metrics\n",
    "\n",
    "Metrics are human-readable performance measures:\n",
    "\n",
    "- **Error Rate**: Percentage of incorrect predictions (lower is better).\n",
    "- **Accuracy**: Percentage of correct predictions (higher is better).\n",
    "\n",
    "### Batch Size\n",
    "\n",
    "The number of images processed together:\n",
    "\n",
    "- Larger batch size: More stable gradients, but requires more memory.\n",
    "- Smaller batch size: Less memory required, but training may be less stable.\n",
    "\n",
    "### Learning Rate\n",
    "\n",
    "Controls how quickly weights update:\n",
    "\n",
    "- Too high: Model may never converge.\n",
    "- Too low: Training takes too long.\n",
    "- One-cycle policy: Start low, increase then decrease (better convergence).\n",
    "\n",
    "I hope this detailed explanation helps you understand the process of building an image classifier with fastai! Would you like me to explain any particular concept in more depth?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
